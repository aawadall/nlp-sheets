{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm6UT-3OL2C8"
      },
      "source": [
        "# NLP Experiment 1: Word Embeddings\n",
        "Experimenting With NLP using NLTK and Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykFUpKXZL8I2"
      },
      "source": [
        "## Load Required Libraries\n",
        "Load libraries expected for this experiment:\n",
        "\n",
        "- [ ] nltk \n",
        "- [ ] nltk.word_tokenize \n",
        "- [ ] spacy.lang.en.English \n",
        "- [ ] gensim \n",
        "- [ ] numpy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nltk in /home/ahmed/.local/lib/python3.10/site-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /home/ahmed/.local/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /home/ahmed/.local/lib/python3.10/site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/ahmed/.local/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /home/ahmed/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: spacy in /home/ahmed/.local/lib/python3.10/site-packages (3.4.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (1.23.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (0.10.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ahmed/.local/lib/python3.10/site-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/ahmed/.local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ahmed/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ahmed/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ahmed/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ahmed/.local/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ahmed/.local/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Local only \n",
        "!pip install --upgrade nltk\n",
        "!pip install --upgrade spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SKF750bGMsAw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmed/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2022-12-01 10:23:07.924871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-12-01 10:23:07.924890: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-12-01 10:23:09.508888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-12-01 10:23:09.508916: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-12-01 10:23:09.508934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aawadall): /proc/driver/nvidia/version does not exist\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize \n",
        "from spacy.lang.en import English \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ1IWUONNCog",
        "outputId": "a02ceb38-6dee-4a4c-f32e-bc6b34fca415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gensim in /home/ahmed/.local/lib/python3.10/site-packages (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /home/ahmed/.local/lib/python3.10/site-packages (from gensim) (1.23.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /home/ahmed/.local/lib/python3.10/site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /home/ahmed/.local/lib/python3.10/site-packages (from gensim) (1.9.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QNuXdyEZNIxX"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api \n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtuwFbKfNRJN"
      },
      "source": [
        "Download word2vec, this may take some time "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "5gtUk2djNV1S",
        "outputId": "b641f2c6-0770-45bb-bfed-8caf23b424c0"
      },
      "outputs": [],
      "source": [
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuQiR4m_NjEf"
      },
      "source": [
        "## Define Sample Text\n",
        "define a couple of sample text strings and run some analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NktwZiktNseA"
      },
      "outputs": [],
      "source": [
        "simple_str = \"This is a simple string, used to test tokenization. It may have minimal information in it, but used to illustrate how to extract word embeddings\"\n",
        "strings_vector = [\n",
        "    \"Patiance is a virtue\",\n",
        "    \"The sum of one and two is \",\n",
        "    \"better safe than sorry\",\n",
        "    \"you cannot divide a number by zero\",\n",
        "    \"are we there yet?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_mRDtlPcvE"
      },
      "source": [
        "## Sentence Concept \n",
        "Define a class of functions to extract the gist of a sentence using an aggregate of word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rQQnmmXLP23w"
      },
      "outputs": [],
      "source": [
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer\n",
        "def normalized_sum(sentence):\n",
        "  \"\"\"\n",
        "  Calculates normalized sum of word embeddings of tokens in a sentence\n",
        "  \"\"\"\n",
        "\n",
        "  toks = tokenizer(sentence)\n",
        "  sum = []\n",
        "  for token in toks:\n",
        "    try: \n",
        "      v = wv[token.text]\n",
        "      if len(sum) == 0:\n",
        "        sum = v\n",
        "      else:\n",
        "        sum = sum + v \n",
        "    except:\n",
        "      continue\n",
        "  # normalize \n",
        "  sum = sum / np.linalg.norm(sum)\n",
        "  return sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTmKMKi6Rvts"
      },
      "source": [
        "## Calculate Normalized Sum \n",
        "Calculate normalized sum for sample sentences "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2f2huOAMR4KO"
      },
      "outputs": [],
      "source": [
        "simple_str_ns = normalized_sum(simple_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Simple String Embedding\n",
        "find closest words matching this concept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('By_Laurelle_Gilbert', 0.6034723520278931),\n",
              " ('%_#F########_9v.jsn', 0.5943512916564941),\n",
              " ('BY_ANDY_THOMPSON', 0.589264988899231),\n",
              " ('By_Jonas_Elmerraji', 0.585291862487793),\n",
              " ('it', 0.585139811038971),\n",
              " ('A.It_s', 0.5839791297912598),\n",
              " ('that', 0.5821940898895264),\n",
              " ('AThere', 0.5760250687599182),\n",
              " ('but', 0.5712571740150452),\n",
              " ('GREG_POTTER_Yes', 0.5703470706939697)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wv.most_similar(simple_str_ns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Try for other sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patiance is a virtue\n",
            "[('virtue', 0.836878776550293), ('is', 0.6671273112297058), ('means', 0.578962504863739), ('presupposes', 0.5349286794662476), ('dint', 0.5220244526863098), ('becomes', 0.4905795454978943), (\"isn'ta\", 0.48826590180397034), ('seems', 0.48623791337013245), ('dictates', 0.481949120759964), ('virture', 0.47703272104263306)]\n",
            "The sum of one and two is \n",
            "[('one', 0.673549473285675), ('sum', 0.628027081489563), ('two', 0.5564963817596436), ('three', 0.5492445230484009), ('the', 0.5443174242973328), ('four', 0.539329469203949), ('five', 0.532472550868988), ('is', 0.5301937460899353), ('The', 0.5249226689338684), ('six', 0.5138891935348511)]\n",
            "better safe than sorry\n",
            "[('better', 0.7288674712181091), ('sorry', 0.6563988924026489), ('safe', 0.6418575048446655), ('safer', 0.6321291327476501), ('sorry_Semaitis', 0.618122935295105), ('happier', 0.5762538313865662), ('nicer', 0.5709905624389648), ('TV6_wonders', 0.5573280453681946), ('sorrier', 0.5523179173469543), ('Johnnie_Baston_die', 0.5482122898101807)]\n",
            "you cannot divide a number by zero\n",
            "[('can', 0.6353193521499634), ('not', 0.6165188550949097), ('you', 0.6003228425979614), ('do', 0.5930917263031006), ('they', 0.5682259202003479), ('AWell', 0.5661731958389282), ('just', 0.5656866431236267), ('QDo', 0.5572266578674316), ('actually', 0.554905891418457), ('that', 0.5464920401573181)]\n",
            "are we there yet?\n",
            "[('we', 0.7336916923522949), ('there', 0.7173899412155151), ('they', 0.6653739809989929), (\"'re\", 0.6484829783439636), ('are', 0.6478847861289978), ('not', 0.6304683685302734), ('yet', 0.6262755990028381), ('have', 0.6164054274559021), ('still', 0.6158721446990967), ('do', 0.6152428388595581)]\n"
          ]
        }
      ],
      "source": [
        "for s in strings_vector:\n",
        "  print(s)\n",
        "  print(wv.most_similar(normalized_sum(s)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dot Product\n",
        "find the dot product of all word embeddings in a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(sentence):\n",
        "    \"\"\"\n",
        "    Define a function to calculate the \n",
        "    resulting cosine similarity between\n",
        "    all word embeddings in a sentence\n",
        "    \"\"\"\n",
        "    toks = tokenizer(sentence)\n",
        "    sim = None\n",
        "    for token in toks:\n",
        "        try:\n",
        "            v = wv[token.text]\n",
        "            if sim == None:\n",
        "                sim = v \n",
        "                print('first', sim)\n",
        "            else:\n",
        "                sim = np.linalg.multi_dot(sim, v)\n",
        "                print(sim)\n",
        "        except:\n",
        "            continue\n",
        "    return sim / np.linalg.norm(sim)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a simple string, used to test tokenization. It may have minimal information in it, but used to illustrate how to extract word embeddings\n",
            "first [-0.2890625   0.19921875  0.16015625  0.02526855 -0.23632812  0.10205078\n",
            "  0.06640625 -0.16503906  0.12597656  0.22070312  0.05517578 -0.28710938\n",
            " -0.02148438  0.05541992  0.01574707  0.29296875  0.19433594 -0.01531982\n",
            "  0.03955078 -0.21484375  0.00994873  0.16015625  0.07958984 -0.05932617\n",
            "  0.12353516 -0.27148438 -0.10205078  0.078125   -0.07519531  0.22363281\n",
            "  0.16210938 -0.04614258  0.12304688  0.07275391  0.25        0.0072937\n",
            " -0.38867188  0.10644531  0.20996094  0.06103516  0.10107422  0.16894531\n",
            " -0.15429688 -0.08251953  0.06542969 -0.12255859 -0.11621094  0.04248047\n",
            "  0.08251953  0.09716797 -0.05371094  0.125       0.15039062 -0.09228516\n",
            "  0.23925781  0.15234375  0.1796875  -0.26171875  0.15429688  0.09619141\n",
            " -0.30859375 -0.05224609 -0.18652344 -0.24414062 -0.0612793  -0.12695312\n",
            "  0.14160156 -0.03295898  0.03759766 -0.09863281  0.07324219 -0.046875\n",
            "  0.08203125  0.02441406  0.11425781  0.05200195  0.02685547  0.04931641\n",
            "  0.11035156  0.44921875  0.07519531 -0.06835938 -0.10351562  0.06591797\n",
            " -0.15234375 -0.21484375 -0.09179688  0.37109375 -0.07470703 -0.08886719\n",
            "  0.12255859 -0.12792969 -0.12597656 -0.23632812  0.06225586  0.05957031\n",
            "  0.08251953  0.05297852 -0.17871094  0.21289062  0.00241089 -0.05786133\n",
            "  0.02563477 -0.01434326  0.00646973 -0.0703125  -0.08398438 -0.18652344\n",
            " -0.24707031 -0.21484375 -0.01269531 -0.02416992  0.14746094  0.20214844\n",
            "  0.19140625  0.06738281  0.02307129  0.05297852 -0.02258301  0.30664062\n",
            " -0.10791016 -0.22460938 -0.10498047  0.06884766  0.07226562  0.07373047\n",
            " -0.11474609 -0.11474609  0.05883789 -0.12109375 -0.15136719  0.04101562\n",
            " -0.09863281  0.06982422  0.32617188 -0.27929688 -0.12255859 -0.12890625\n",
            " -0.12890625  0.19042969  0.171875   -0.05371094 -0.2734375  -0.08496094\n",
            " -0.12695312 -0.24121094  0.09082031 -0.14355469 -0.0703125   0.06396484\n",
            "  0.08007812 -0.20605469  0.03930664  0.04589844  0.0612793  -0.23339844\n",
            "  0.31835938 -0.04956055 -0.03417969 -0.31445312 -0.18066406  0.00842285\n",
            " -0.00765991  0.09423828  0.11865234  0.02722168  0.08398438  0.07128906\n",
            " -0.23339844  0.21777344 -0.17480469  0.05517578  0.08642578 -0.14746094\n",
            " -0.03833008  0.18359375  0.21484375 -0.28125     0.04980469 -0.20800781\n",
            " -0.01177979 -0.08007812 -0.09521484  0.09375    -0.01721191  0.16601562\n",
            " -0.06787109  0.18261719  0.26757812  0.08056641 -0.01373291 -0.16601562\n",
            "  0.13867188 -0.18847656 -0.07666016 -0.29101562 -0.16015625  0.32617188\n",
            " -0.04296875 -0.22558594  0.02868652 -0.25195312  0.08935547  0.203125\n",
            " -0.09375     0.07763672  0.00741577  0.19726562  0.14648438 -0.02148438\n",
            "  0.01611328  0.34570312  0.02990723  0.15625     0.08984375  0.1875\n",
            "  0.06787109  0.04785156 -0.03417969  0.10546875  0.12402344 -0.07177734\n",
            "  0.05981445 -0.03491211  0.10400391 -0.12353516  0.07470703  0.04541016\n",
            "  0.15625     0.02734375  0.00386047 -0.05444336  0.16015625  0.08447266\n",
            " -0.1640625   0.03833008 -0.20800781  0.16015625  0.00065994  0.26367188\n",
            "  0.08496094 -0.23339844 -0.11914062 -0.06494141  0.04736328  0.04980469\n",
            "  0.14941406  0.02099609  0.06201172 -0.16894531  0.171875    0.11865234\n",
            " -0.1875      0.16796875  0.08105469 -0.10595703  0.27539062 -0.20507812\n",
            " -0.06884766 -0.10839844 -0.04467773 -0.00872803 -0.06689453 -0.16308594\n",
            " -0.109375    0.17089844  0.18066406 -0.10351562 -0.265625   -0.03442383\n",
            " -0.06445312  0.28320312  0.13867188  0.10400391  0.10498047 -0.10791016\n",
            "  0.34960938 -0.12158203  0.10644531 -0.11425781 -0.07568359  0.03491211\n",
            "  0.15332031  0.26367188  0.11279297 -0.08349609 -0.15625    -0.203125\n",
            " -0.20605469  0.0255127  -0.2265625  -0.02478027 -0.13378906  0.04907227\n",
            " -0.1328125  -0.27539062  0.00463867  0.12792969  0.12109375 -0.22949219]\n",
            "[-0.11104227  0.07652913  0.06152342  0.00970682 -0.09078456  0.03920242\n",
            "  0.02550971 -0.06339914  0.04839342  0.08478227  0.02119557 -0.11029198\n",
            " -0.00825314  0.02128935  0.00604918  0.11254284  0.07465342 -0.00588505\n",
            "  0.01519328 -0.08253141  0.00382177  0.06152342  0.03057414 -0.02278993\n",
            "  0.04745556 -0.1042897  -0.03920242  0.03001142 -0.028886    0.0859077\n",
            "  0.0622737  -0.0177255   0.04726799  0.02794814  0.09603655  0.00280185\n",
            " -0.14930683  0.04089056  0.0806557   0.02344642  0.03882728  0.06489971\n",
            " -0.05927256 -0.03169957  0.02513457 -0.04708042 -0.04464199  0.01631871\n",
            "  0.03169957  0.03732671 -0.02063285  0.04801828  0.05777199 -0.03545099\n",
            "  0.09190998  0.05852228  0.06902628 -0.10053827  0.05927256  0.03695156\n",
            " -0.11854512 -0.02007014 -0.07165227 -0.0937857  -0.02354021 -0.04876857\n",
            "  0.05439571 -0.01266107  0.014443   -0.03788942  0.02813571 -0.01800685\n",
            "  0.031512    0.00937857  0.04389171  0.01997635  0.01031643  0.01894471\n",
            "  0.04239114  0.17256568  0.028886   -0.02626    -0.03976514  0.02532214\n",
            " -0.05852228 -0.08253141 -0.03526342  0.14255427 -0.02869842 -0.03413799\n",
            "  0.04708042 -0.04914371 -0.04839342 -0.09078456  0.02391535  0.02288371\n",
            "  0.03169957  0.0203515  -0.06865113  0.08178113  0.00092613 -0.02222721\n",
            "  0.0098475  -0.00550991  0.00248532 -0.02701028 -0.03226228 -0.07165227\n",
            " -0.09491113 -0.08253141 -0.00487686 -0.00928478  0.05664656  0.07765456\n",
            "  0.07352799  0.02588485  0.00886275  0.0203515  -0.00867518  0.11779484\n",
            " -0.04145328 -0.08628284 -0.04032785  0.02644757  0.02776057  0.02832328\n",
            " -0.04407928 -0.04407928  0.02260235 -0.04651771 -0.05814713  0.015756\n",
            " -0.03788942  0.02682271  0.1252977  -0.10729084 -0.04708042 -0.04951885\n",
            " -0.04951885  0.07315285  0.06602513 -0.02063285 -0.10503998 -0.03263742\n",
            " -0.04876857 -0.09266027  0.03488828 -0.05514599 -0.02701028  0.02457185\n",
            "  0.03076171 -0.07915513  0.0150995   0.01763171  0.02354021 -0.08965913\n",
            "  0.12229655 -0.0190385  -0.01313    -0.12079598 -0.06940142  0.00323561\n",
            " -0.00294253  0.03620128  0.04557985  0.01045711  0.03226228  0.02738542\n",
            " -0.08965913  0.08365684 -0.06715056  0.02119557  0.03320014 -0.05664656\n",
            " -0.01472436  0.07052685  0.08253141 -0.10804112  0.01913228 -0.07990541\n",
            " -0.00452516 -0.03076171 -0.03657642  0.03601371 -0.00661189  0.06377427\n",
            " -0.02607242  0.0701517   0.10278913  0.03094928 -0.00527545 -0.06377427\n",
            "  0.05327028 -0.07240256 -0.02944871 -0.11179256 -0.06152342  0.1252977\n",
            " -0.01650628 -0.08665799  0.01101982 -0.09678684  0.03432557  0.0780297\n",
            " -0.03601371  0.02982385  0.00284874  0.07577884  0.05627142 -0.00825314\n",
            "  0.00618986  0.13280055  0.01148875  0.06002285  0.03451314  0.07202742\n",
            "  0.02607242  0.018382   -0.01313     0.04051542  0.04764314 -0.027573\n",
            "  0.0229775  -0.01341136  0.03995271 -0.04745556  0.02869842  0.01744414\n",
            "  0.06002285  0.010504    0.00148299 -0.02091421  0.06152342  0.03244985\n",
            " -0.06302399  0.01472436 -0.07990541  0.06152342  0.00025351  0.10128856\n",
            "  0.03263742 -0.08965913 -0.04576742 -0.024947    0.01819443  0.01913228\n",
            "  0.05739685  0.00806557  0.02382157 -0.06489971  0.06602513  0.04557985\n",
            " -0.07202742  0.06452456  0.03113685 -0.04070299  0.10579026 -0.07877999\n",
            " -0.02644757 -0.04164085 -0.01716278 -0.00335284 -0.02569728 -0.06264885\n",
            " -0.04201599  0.06564999  0.06940142 -0.03976514 -0.10203884 -0.01322378\n",
            " -0.02475942  0.10879141  0.05327028  0.03995271  0.04032785 -0.04145328\n",
            "  0.13430113 -0.04670528  0.04089056 -0.04389171 -0.02907357  0.01341136\n",
            "  0.05889742  0.10128856  0.04332899 -0.03207471 -0.06002285 -0.0780297\n",
            " -0.07915513  0.00980061 -0.08703313 -0.00951925 -0.05139456  0.01885093\n",
            " -0.05101942 -0.10579026  0.00178193  0.04914371  0.04651771 -0.08815856]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('This', 1.0),\n",
              " ('It', 0.8164012432098389),\n",
              " ('That', 0.8073375225067139),\n",
              " ('The', 0.7025192379951477),\n",
              " (\"It'sa\", 0.6968192458152771),\n",
              " ('â_€_œThis', 0.6586222648620605),\n",
              " (\"That'sa\", 0.6455750465393066),\n",
              " ('Perhaps', 0.6198620796203613),\n",
              " ('More_importantly', 0.6120434999465942),\n",
              " ('Secondly', 0.6081434488296509)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(simple_str)\n",
        "simple_str_cs = cosine_similarity(simple_str)\n",
        "print(simple_str_cs)\n",
        "wv.most_similar(simple_str_cs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Moving Average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def moving_avg(sentence):\n",
        "    \"\"\"\n",
        "    Define a function to calculate the\n",
        "    moving average of word embeddings\n",
        "    for tokens in a sentence\n",
        "    \"\"\"\n",
        "    toks = tokenizer(sentence)\n",
        "    avg = None\n",
        "    old = 0.7\n",
        "    new = 0.3\n",
        "    for token in toks:\n",
        "        if token.is_stop:\n",
        "            continue\n",
        "        try:\n",
        "            v = wv[token.text]\n",
        "            if avg == None:\n",
        "                avg = v\n",
        "            else:\n",
        "                avg = old * avg + v * new \n",
        "        except:\n",
        "            continue\n",
        "    return avg / np.linalg.norm(avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Moving Average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.12323125 -0.03021913 -0.02109452  0.01383408 -0.09968388  0.02286058\n",
            "  0.14991827  0.04415132 -0.00642647  0.04081545  0.01040009 -0.00042618\n",
            " -0.01726807  0.07574405 -0.02070207  0.04630983  0.14128424 -0.03944185\n",
            " -0.0474872  -0.01501145  0.00431702  0.107533   -0.00603401  0.00716233\n",
            " -0.00328682 -0.02668702 -0.00726044  0.01103783 -0.01628693 -0.01147934\n",
            " -0.06514774  0.05926089  0.07378177 -0.00721138 -0.06318545  0.03787202\n",
            "  0.02148698  0.00505287  0.02668702  0.00130001  0.04905703  0.04650606\n",
            "  0.0886951  -0.02727571  0.03983431 -0.04317018 -0.06475528  0.0788837\n",
            "  0.01716996 -0.05533633 -0.0600458  -0.01025292  0.02904176 -0.08084598\n",
            " -0.01648316  0.05141176 -0.04493624 -0.107533   -0.02668702  0.00416985\n",
            " -0.00603401  0.01442277  0.01383408  0.00667176  0.04905703 -0.01599259\n",
            " -0.11852178  0.02570588  0.0474872   0.00745667  0.10203861 -0.01864167\n",
            "  0.0488608  -0.02943422 -0.11145756 -0.02727571  0.0565137   0.0726044\n",
            "  0.05533633  0.10203861 -0.05729861 -0.01824921 -0.00108539  0.04807589\n",
            "  0.06240054 -0.13657476 -0.09497441  0.00414532  0.0600458   0.00247738\n",
            " -0.01756242  0.00023149 -0.09536686 -0.08398563 -0.06318545  0.03237764\n",
            " -0.06043826 -0.0914423  -0.0565137   0.06200808 -0.00591137  0.05062685\n",
            " -0.01353974 -0.01304917 -0.07692142 -0.02158509  0.05415896 -0.05219668\n",
            "  0.04905703 -0.01211709 -0.0788837   0.02786439 -0.09183475 -0.01491334\n",
            "  0.1389295   0.09889897  0.03178895 -0.03963808 -0.01295106  0.06789493\n",
            " -0.10674809 -0.02806062 -0.0886951  -0.03689088  0.0139322   0.07142703\n",
            " -0.033555    0.05219668  0.09222721  0.07966861 -0.12087651 -0.10203861\n",
            "  0.00686798  0.0753516   0.06122317  0.03041536  0.04964571  0.00424343\n",
            "  0.0188379   0.03826448  0.00348305 -0.05415896  0.01412842  0.01726807\n",
            " -0.1326502  -0.00544533 -0.11224248 -0.07103457  0.08123843 -0.02550965\n",
            "  0.0006776  -0.02197755  0.00578873  0.00096888 -0.03590974 -0.01471711\n",
            "  0.02433228  0.01383408 -0.03316255  0.03178895 -0.07103457  0.13029547\n",
            " -0.0132454  -0.07064212  0.02119264 -0.07809879 -0.03277009 -0.07221194\n",
            " -0.05494387 -0.04944948 -0.06867984  0.0013552  -0.10282353  0.01461899\n",
            " -0.02649079  0.1318653  -0.00598496  0.01638505 -0.1012537   0.0202115\n",
            " -0.02786439 -0.05769106 -0.01824921 -0.0412079   0.0663251   0.1389295\n",
            " -0.00537174 -0.0057642   0.02904176 -0.00556797 -0.13343512  0.06475528\n",
            "  0.04532869 -0.04375887 -0.07456668 -0.01981904 -0.06946475 -0.07849124\n",
            " -0.03061159 -0.09379704  0.04297395  0.0488608  -0.0753516   0.07613651\n",
            "  0.00951706  0.03610597 -0.03120027 -0.07181948 -0.00123256 -0.04866457\n",
            " -0.05847597  0.0886951   0.01707185  0.02344926 -0.00251417 -0.00293116\n",
            "  0.05180422  0.0474872  -0.08202335  0.08751774  0.02295869  0.05141176\n",
            " -0.04925326 -0.04807589 -0.01618882 -0.03257387  0.08908756 -0.08437809\n",
            "  0.04964571  0.05062685  0.00387551  0.01520768  0.05533633  0.04160036\n",
            " -0.00419438 -0.07692142 -0.02550965  0.03806825  0.01697373  0.01913224\n",
            "  0.01648316 -0.0125586  -0.10046879 -0.06593265  0.02550965  0.04630983\n",
            " -0.01442277  0.07456668  0.00041698 -0.07692142 -0.09418949  0.06122317\n",
            "  0.1012537   0.02286058  0.05062685 -0.03237764 -0.07849124 -0.05808352\n",
            "  0.03277009 -0.06357791  0.06122317 -0.10046879 -0.04061922 -0.12166142\n",
            " -0.04101168  0.06514774  0.01628693 -0.11616704 -0.03983431 -0.02668702\n",
            "  0.08634037 -0.00858498 -0.03277009 -0.03944185  0.00156369  0.02060395\n",
            "  0.02766816 -0.08123843  0.01138123  0.03708711  0.02050584  0.02845308\n",
            " -0.01942658 -0.06318545 -0.07064212  0.04964571 -0.02550965  0.0073095\n",
            " -0.03532106  0.10596318 -0.05886843  0.05455142  0.0244304   0.02197755\n",
            " -0.0300229   0.02707948  0.10046879  0.01103783 -0.02570588  0.0565137 ]\n",
            "This is a simple string, used to test tokenization. It may have minimal information in it, but used to illustrate how to extract word embeddings\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('simple', 1.0),\n",
              " ('straightforward', 0.7460168600082397),\n",
              " ('Simple', 0.7108174562454224),\n",
              " ('uncomplicated', 0.6297484636306763),\n",
              " ('simplest', 0.6171397566795349),\n",
              " ('easy', 0.5990299582481384),\n",
              " ('fairly_straightforward', 0.5893306732177734),\n",
              " ('deceptively_simple', 0.5743065476417542),\n",
              " ('simpler', 0.5537199974060059),\n",
              " ('simplistic', 0.5516539216041565)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_str_ma = moving_avg(simple_str)\n",
        "print(simple_str_ma)\n",
        "print(simple_str)\n",
        "wv.most_similar(simple_str_ma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Moving Average on other data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patiance is a virtue\n",
            "[('virtue', 1.0), ('dint', 0.6641983985900879), ('virture', 0.5358221530914307), ('Uncommon_valor', 0.5161334276199341), ('Imam_Mohammed_Sadiq', 0.512965202331543), ('disinterestedness', 0.5091259479522705), ('Father_Skehan', 0.49249526858329773), ('exalted', 0.4778507947921753), ('Selflessness', 0.4691542088985443), ('exemplification', 0.45130637288093567)]\n",
            "The sum of one and two is \n",
            "[('sum', 1.0000001192092896), ('sums', 0.743831992149353), ('amount', 0.6335751414299011), ('amounts', 0.5367383360862732), ('amout', 0.5301712155342102), ('outlay', 0.5228390693664551), ('GH_¢_###,###,###.##', 0.5000982880592346), ('N5million', 0.4885185956954956), ('Sums', 0.4867772161960602), ('paltry_sum', 0.47490522265434265)]\n",
            "better safe than sorry\n",
            "[('better', 1.0), ('stronger', 0.6623841524124146), ('quicker', 0.6499592065811157), ('smarter', 0.6418017148971558), ('worse', 0.6248995065689087), ('good', 0.6120728850364685), ('happier', 0.594508707523346), ('nicer', 0.590819239616394), ('easier', 0.5893970131874084), ('harder', 0.5786380767822266)]\n",
            "you cannot divide a number by zero\n",
            "[('divide', 1.0), ('divides', 0.7381654381752014), ('dividing', 0.6746436953544617), ('divided', 0.6347422003746033), ('chasm', 0.5956025719642639), ('rift', 0.5836583971977234), ('rifts', 0.5666654706001282), ('widening_gulf', 0.5594594478607178), ('widening_chasm', 0.5592597723007202), ('differences', 0.5590852499008179)]\n",
            "are we there yet?\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for *: 'NoneType' and 'NoneType'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m strings_vector:\n\u001b[1;32m      2\u001b[0m   \u001b[39mprint\u001b[39m(s)\n\u001b[0;32m----> 3\u001b[0m   \u001b[39mprint\u001b[39m(wv\u001b[39m.\u001b[39mmost_similar(moving_avg(s)))\n",
            "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mmoving_avg\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mreturn\u001b[39;00m avg \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(avg)\n",
            "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py:2526\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2524\u001b[0m     sqnorm \u001b[39m=\u001b[39m x_real\u001b[39m.\u001b[39mdot(x_real) \u001b[39m+\u001b[39m x_imag\u001b[39m.\u001b[39mdot(x_imag)\n\u001b[1;32m   2525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2526\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(x)\n\u001b[1;32m   2527\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2528\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'NoneType'"
          ]
        }
      ],
      "source": [
        "for s in strings_vector:\n",
        "  print(s)\n",
        "  print(wv.most_similar(moving_avg(s)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Internal WV Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wv_prod(string):\n",
        "    \"\"\"Use Existing WV method\"\"\"\n",
        "    main_toks = [ t for t in tokenizer(string) ]\n",
        "    toks = []\n",
        "    for t in main_toks:\n",
        "        try:\n",
        "            v = wv[t.text]\n",
        "            if not t.is_stop:\n",
        "                toks.append(t.text)\n",
        "        except:\n",
        "            continue\n",
        "    return wv.most_similar_cosmul(positive=toks, negative=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test for simple sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Base##_encoding', 0.014345054514706135), ('fuzzing_tools', 0.01340305246412754), ('preemptive_ThreatSeeker_TM', 0.013388464227318764), ('alphabetic_characters', 0.01333235390484333), ('lnk_files', 0.01331906858831644), ('charts_graphs_maps', 0.013317907229065895), ('nonstandardized', 0.013066706247627735), ('NIST_MINEX_compliant', 0.012996304780244827), ('algebraic_formula', 0.012968824245035648), ('Javascript_extensively', 0.012934676371514797)]\n",
            "This is a simple string, used to test tokenization. It may have minimal information in it, but used to illustrate how to extract word embeddings\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('window.open', 0.745729923248291),\n",
              " ('TITLE_Debian_update', 0.7442658543586731),\n",
              " ('SOLUTION_Restrict_access', 0.7414754033088684),\n",
              " ('Display_Coleman_Liau', 0.7405574917793274),\n",
              " ('DIRECTORS_OF_CAPITAL_CORP.', 0.7392650842666626),\n",
              " ('inferential_statistics', 0.7367329597473145),\n",
              " ('xls_files', 0.727687656879425),\n",
              " ('MGRS_Military_grid', 0.7265646457672119),\n",
              " ('LINQ_queries', 0.7253888845443726),\n",
              " ('By_Miriam_Reimer', 0.7237569093704224)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_str_wv = wv_prod(simple_str)\n",
        "print(simple_str_wv)\n",
        "print(simple_str)\n",
        "wv.most_similar(simple_str_wv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test for other sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patiance is a virtue\n",
            "[('virtue', 0.7619860172271729), ('unmerited_favor', 0.6585700511932373), ('Honesty_integrity', 0.65229731798172), ('dutifulness', 0.650239884853363), ('gentleness_kindness', 0.6296283006668091), ('dauntless_courage', 0.6238256096839905), ('omnipotent_omniscient', 0.6219653487205505), ('Graciousness', 0.6212397813796997), ('whoever_humbles', 0.6209989786148071), ('moral_uprightness', 0.6154956817626953)]\n",
            "The sum of one and two is \n",
            "[('sum', 0.8194766640663147), ('N4_###,###,###.##', 0.6124118566513062), ('N1_###,###,###', 0.5915540456771851), ('GH_¢_##,###,###.##', 0.5894641280174255), ('amountof', 0.5883204340934753), ('N##.###bn', 0.5862666964530945), ('N2_###,###.##', 0.5857111215591431), ('N4_###,###,###', 0.5802429914474487), ('N5billion', 0.5800169706344604), ('Sh##million', 0.5774497985839844)]\n",
            "better safe than sorry\n",
            "[('Said_Hirschbeck', 0.742898166179657), ('safe_Arlene_Deche', 0.7359633445739746), ('nurse_practitioner_Nunez', 0.7296922206878662), ('numb_Gwen_Bacquet', 0.7285842895507812), ('safe_Deche', 0.7275089025497437), ('guessed_Weitzman', 0.7140584588050842), ('shocked_Khubani', 0.7101832628250122), (\"Well_how're\", 0.7099193930625916), ('phenomenally_manipulative', 0.7087880969047546), ('NOVAK_DJOKOVIC_Yeah', 0.7076418399810791)]\n",
            "you cannot divide a number by zero\n",
            "[('disproportion', 0.5776875615119934), ('proportionately', 0.5637180805206299), ('divide', 0.5634515285491943), ('_Among', 0.5541926026344299), ('gini_coefficient', 0.5417084693908691), ('deciles', 0.5394157767295837), ('disparities', 0.5393581390380859), ('per_centage', 0.5377155542373657), ('Underrepresented_minorities', 0.5365667939186096), ('noncollege_educated', 0.533731997013092)]\n",
            "are we there yet?\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot compute similarity with no input",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m strings_vector:\n\u001b[1;32m      2\u001b[0m   \u001b[39mprint\u001b[39m(s)\n\u001b[0;32m----> 3\u001b[0m   \u001b[39mprint\u001b[39m(wv\u001b[39m.\u001b[39mmost_similar(wv_prod(s)))\n",
            "Cell \u001b[0;32mIn[16], line 12\u001b[0m, in \u001b[0;36mwv_prod\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mreturn\u001b[39;00m wv\u001b[39m.\u001b[39;49mmost_similar_cosmul(positive\u001b[39m=\u001b[39;49mtoks, negative\u001b[39m=\u001b[39;49m[])\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/models/keyedvectors.py:1086\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar_cosmul\u001b[0;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m   1080\u001b[0m negative \u001b[39m=\u001b[39m [\n\u001b[1;32m   1081\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(word, norm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(word, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m word\n\u001b[1;32m   1082\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m negative\n\u001b[1;32m   1083\u001b[0m ]\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m positive:\n\u001b[0;32m-> 1086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot compute similarity with no input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1088\u001b[0m \u001b[39m# equation (4) of Levy & Goldberg \"Linguistic Regularities...\",\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[39m# with distances shifted to [0,1] per footnote (7)\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m pos_dists \u001b[39m=\u001b[39m [((\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m dot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectors, term) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mfor\u001b[39;00m term \u001b[39min\u001b[39;00m positive]\n",
            "\u001b[0;31mValueError\u001b[0m: cannot compute similarity with no input"
          ]
        }
      ],
      "source": [
        "for s in strings_vector:\n",
        "  print(s)\n",
        "  print(wv.most_similar(wv_prod(s)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "int method(List<string> list) \n",
            "{\n",
            "    int count = 0;\n",
            "    for (int i = 0; i < list.size(); i++) {\n",
            "        if (list.get(i).equals(\"test\")) {\n",
            "            count++;\n",
            "        }\n",
            "    }\n",
            "    return count;\n",
            "}\n",
            "\n",
            "normalized sum\n",
            "[('int', 0.7454499006271362), ('=_strlen', 0.668779194355011), ('=', 0.6647939682006836), ('=_argv', 0.6594706773757935), ('Automatic_Fuel_Injected_SILVE', 0.6416589021682739), ('len_=', 0.6287344694137573), ('strlen', 0.6204768419265747), ('==_NULL', 0.6156640648841858), ('=_null_&&', 0.6144644021987915), ('#_endif', 0.614333987236023)]\n",
            "moving average\n",
            "[('int', 1.0000001192092896), ('Bearing_Liabilities_incl.', 0.5867320895195007), ('ent', 0.5760172605514526), ('main_int_argc', 0.5722032785415649), ('ot', 0.569582462310791), ('te', 0.5633426904678345), ('nt', 0.5594090819358826), ('tr', 0.5539928674697876), ('ar', 0.5524088740348816), ('......', 0.549221932888031)]\n",
            "word2vec\n",
            "[('0_document.write', 0.8930276036262512), ('=_sizeof', 0.8857088685035706), ('0_document.write_sline', 0.8804425001144409), ('dpa_dg', 0.8802988529205322), ('dpa_si', 0.8659135699272156), ('0_&&', 0.8634930849075317), ('==_null', 0.859734058380127), ('dpa_nr', 0.8577459454536438), ('+_+_className', 0.8565471768379211), ('dpa_fm', 0.8562432527542114)]\n"
          ]
        }
      ],
      "source": [
        "# for fun experiment, test code snippets \n",
        "\n",
        "test_1 = \"\"\"\n",
        "int method(List<string> list) \n",
        "{\n",
        "    int count = 0;\n",
        "    for (int i = 0; i < list.size(); i++) {\n",
        "        if (list.get(i).equals(\"test\")) {\n",
        "            count++;\n",
        "        }\n",
        "    }\n",
        "    return count;\n",
        "}\n",
        "\"\"\"\n",
        "test_1_ns = normalized_sum(test_1)\n",
        "test_1_ma = moving_avg(test_1)\n",
        "test_1_wv = wv_prod(test_1)\n",
        "\n",
        "print(test_1)\n",
        "print('normalized sum')\n",
        "print(wv.most_similar(test_1_ns))\n",
        "print('moving average')\n",
        "print(wv.most_similar(test_1_ma))\n",
        "print('word2vec')\n",
        "print(wv.most_similar(test_1_wv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Prime_Minister_Yukio_Hatoyama', 1.0011963844299316),\n",
              " ('Prime_Minister_Taro_Aso', 0.9990742802619934),\n",
              " ('Prime_Minister_Naoto_Kan', 0.9837645888328552),\n",
              " ('Prime_Minister_Junichiro_Koizumi', 0.9818952083587646),\n",
              " ('Shinzo_Abe', 0.9746299982070923),\n",
              " ('Taku_Yamasaki', 0.9643604755401611),\n",
              " ('Yukio_Edano', 0.9625372886657715),\n",
              " ('Nobutaka_Machimura', 0.9612914323806763),\n",
              " ('Taro_Aso', 0.9561181664466858),\n",
              " ('Shigeru_Ishiba', 0.9532682299613953)]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wv.most_similar_cosmul(positive=['Joe_Biden', 'Japan'],negative=['USA'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 5.12695312e-02, -2.23388672e-02, -1.72851562e-01,  1.61132812e-01,\n",
              "       -8.44726562e-02,  5.73730469e-02,  5.85937500e-02, -8.25195312e-02,\n",
              "       -1.53808594e-02, -6.34765625e-02,  1.79687500e-01, -4.23828125e-01,\n",
              "       -2.25830078e-02, -1.66015625e-01, -2.51464844e-02,  1.07421875e-01,\n",
              "       -1.99218750e-01,  1.59179688e-01, -1.87500000e-01, -1.20117188e-01,\n",
              "        1.55273438e-01, -9.91210938e-02,  1.42578125e-01, -1.64062500e-01,\n",
              "       -8.93554688e-02,  2.00195312e-01, -1.49414062e-01,  3.20312500e-01,\n",
              "        3.28125000e-01,  2.44140625e-02, -9.71679688e-02, -8.20312500e-02,\n",
              "       -3.63769531e-02, -8.59375000e-02, -9.86328125e-02,  7.78198242e-03,\n",
              "       -1.34277344e-02,  5.27343750e-02,  1.48437500e-01,  3.33984375e-01,\n",
              "        1.66015625e-02, -2.12890625e-01, -1.50756836e-02,  5.24902344e-02,\n",
              "       -1.07421875e-01, -8.88671875e-02,  2.49023438e-01, -7.03125000e-02,\n",
              "       -1.59912109e-02,  7.56835938e-02, -7.03125000e-02,  1.19140625e-01,\n",
              "        2.29492188e-01,  1.41601562e-02,  1.15234375e-01,  7.50732422e-03,\n",
              "        2.75390625e-01, -2.44140625e-01,  2.96875000e-01,  3.49121094e-02,\n",
              "        2.42187500e-01,  1.35742188e-01,  1.42578125e-01,  1.75781250e-02,\n",
              "        2.92968750e-02, -1.21582031e-01,  2.28271484e-02, -4.76074219e-02,\n",
              "       -1.55273438e-01,  3.14331055e-03,  3.45703125e-01,  1.22558594e-01,\n",
              "       -1.95312500e-01,  8.10546875e-02, -6.83593750e-02, -1.47094727e-02,\n",
              "        2.14843750e-01, -1.21093750e-01,  1.57226562e-01, -2.07031250e-01,\n",
              "        1.36718750e-01, -1.29882812e-01,  5.29785156e-02, -2.71484375e-01,\n",
              "       -2.98828125e-01, -1.84570312e-01, -2.29492188e-01,  1.19140625e-01,\n",
              "        1.53198242e-02, -2.61718750e-01, -1.23046875e-01, -1.86767578e-02,\n",
              "       -6.49414062e-02, -8.15429688e-02,  7.86132812e-02, -3.53515625e-01,\n",
              "        5.24902344e-02, -2.45361328e-02, -5.43212891e-03, -2.08984375e-01,\n",
              "       -2.10937500e-01, -1.79687500e-01,  2.42187500e-01,  2.57812500e-01,\n",
              "        1.37695312e-01, -2.10937500e-01, -2.17285156e-02, -1.38671875e-01,\n",
              "        1.84326172e-02, -1.23901367e-02, -1.59179688e-01,  1.61132812e-01,\n",
              "        2.08007812e-01,  1.03027344e-01,  9.81445312e-02, -6.83593750e-02,\n",
              "       -8.72802734e-03, -2.89062500e-01, -2.14843750e-01, -1.14257812e-01,\n",
              "       -2.21679688e-01,  4.12597656e-02, -3.12500000e-01, -5.59082031e-02,\n",
              "       -9.76562500e-02,  5.81054688e-02, -4.05273438e-02, -1.73828125e-01,\n",
              "        1.64062500e-01, -2.53906250e-01, -1.54296875e-01, -2.31933594e-02,\n",
              "       -2.38281250e-01,  2.07519531e-02, -2.73437500e-01,  3.90625000e-03,\n",
              "        1.13769531e-01, -1.73828125e-01,  2.57812500e-01,  2.35351562e-01,\n",
              "        5.22460938e-02,  6.83593750e-02, -1.75781250e-01,  1.60156250e-01,\n",
              "       -5.98907471e-04,  5.98144531e-02, -2.11914062e-01, -5.54199219e-02,\n",
              "       -7.51953125e-02, -3.06640625e-01,  4.27734375e-01,  5.32226562e-02,\n",
              "       -2.08984375e-01, -5.71289062e-02, -2.09960938e-01,  3.29589844e-02,\n",
              "        1.05468750e-01, -1.50390625e-01, -9.37500000e-02,  1.16699219e-01,\n",
              "        6.44531250e-02,  2.80761719e-02,  2.41210938e-01, -1.25976562e-01,\n",
              "       -1.00585938e-01, -1.22680664e-02, -3.26156616e-04,  1.58691406e-02,\n",
              "        1.27929688e-01, -3.32031250e-02,  4.07714844e-02, -1.31835938e-01,\n",
              "        9.81445312e-02,  1.74804688e-01, -2.36328125e-01,  5.17578125e-02,\n",
              "        1.83593750e-01,  2.42919922e-02, -4.31640625e-01,  2.46093750e-01,\n",
              "       -3.03955078e-02, -2.47802734e-02, -1.17187500e-01,  1.61132812e-01,\n",
              "       -5.71289062e-02,  1.16577148e-02,  2.81250000e-01,  4.27734375e-01,\n",
              "        4.56542969e-02,  1.01074219e-01, -3.95507812e-02,  1.77001953e-02,\n",
              "       -8.98437500e-02,  1.35742188e-01,  2.08007812e-01,  1.88476562e-01,\n",
              "       -1.52343750e-01, -2.37304688e-01, -1.90429688e-01,  7.12890625e-02,\n",
              "       -2.46093750e-01, -2.61718750e-01, -2.34375000e-01, -1.45507812e-01,\n",
              "       -1.17187500e-02, -1.50390625e-01, -1.13281250e-01,  1.82617188e-01,\n",
              "        2.63671875e-01, -1.37695312e-01, -4.58984375e-01, -4.68750000e-02,\n",
              "       -1.26953125e-01, -4.22363281e-02, -1.66992188e-01,  1.26953125e-01,\n",
              "        2.59765625e-01, -2.44140625e-01, -2.19726562e-01, -8.69140625e-02,\n",
              "        1.59179688e-01, -3.78417969e-02,  8.97216797e-03, -2.77343750e-01,\n",
              "       -1.04980469e-01, -1.75781250e-01,  2.28515625e-01, -2.70996094e-02,\n",
              "        2.85156250e-01, -2.73437500e-01,  1.61132812e-02,  5.90820312e-02,\n",
              "       -2.39257812e-01,  1.77734375e-01, -1.34765625e-01,  1.38671875e-01,\n",
              "        3.53515625e-01,  1.22070312e-01,  1.43554688e-01,  9.22851562e-02,\n",
              "        2.29492188e-01, -3.00781250e-01, -4.88281250e-02, -1.79687500e-01,\n",
              "        2.96875000e-01,  1.75781250e-01,  4.80957031e-02, -3.38745117e-03,\n",
              "        7.91015625e-02, -2.38281250e-01, -2.31445312e-01,  1.66015625e-01,\n",
              "       -2.13867188e-01, -7.03125000e-02, -7.56835938e-02,  1.96289062e-01,\n",
              "       -1.29882812e-01, -1.05957031e-01, -3.53515625e-01, -1.16699219e-01,\n",
              "       -5.10253906e-02,  3.39355469e-02, -1.43554688e-01, -3.90625000e-03,\n",
              "        1.73828125e-01, -9.96093750e-02, -1.66015625e-01, -8.54492188e-02,\n",
              "       -3.82812500e-01,  5.90820312e-02, -6.22558594e-02,  8.83789062e-02,\n",
              "       -8.88671875e-02,  3.28125000e-01,  6.83593750e-02, -1.91406250e-01,\n",
              "       -8.35418701e-04,  1.04003906e-01,  1.52343750e-01, -1.53350830e-03,\n",
              "        4.16015625e-01, -3.32031250e-02,  1.49414062e-01,  2.42187500e-01,\n",
              "       -1.76757812e-01, -4.93164062e-02, -1.24511719e-01,  1.25976562e-01,\n",
              "        1.74804688e-01,  2.81250000e-01, -1.80664062e-01,  1.03027344e-01,\n",
              "       -2.75390625e-01,  2.61718750e-01,  2.46093750e-01, -4.71191406e-02,\n",
              "        6.25000000e-02,  4.16015625e-01, -3.55468750e-01,  2.22656250e-01],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wv['dog']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "s_legal = [\n",
        "    \"\"\"17.1 Fair market share for Company A will be based on city pairs in North America for direct routes managed by Delta Airlines.\"\"\",\n",
        "    \"\"\"17.2 Company A will utilize Delta at a fair market share of 60 percent for flights originating in NYC and terminating in SFO.\"\"\",\n",
        "    \"\"\"17.3 A person who is not a party to this Agreement has no right to enforce any of its terms under the Contracts (Rights of Third\n",
        "     Parties) Act 1999.\"\"\",\n",
        "    \"\"\"17.4 Provisions of the Agreement which by their nature should apply beyond their terms, will remain in force after any termination\n",
        "     or expiration of these Terms and Conditions including, but not limited to, the following provisions: Confidential Information,\n",
        "     Governing Law and Submission to Jurisdiction.\"\"\",\n",
        "    \"\"\"17.5 The Customer shall not assign any of its rights or delegate any of its obligations under the Agreement without the prior written\n",
        "     consent of ATPI. Any purported assignment or delegation in violation of this Clause is null and void. No assignment or delegation\n",
        "     relieves the Customer of any of its obligations under the Agreement.\"\"\",\n",
        "    \"\"\"17.6 These Terms and Conditions are solely for the benefit of the Customer and ATPI. It is not for the benefit of any other person,\n",
        "     except for permitted successors and assigns.\"\"\",\n",
        "    \"\"\"17.7 The Agreement comprises the entire agreement between the Parties, and supersedes all prior or contemporaneous\n",
        "     understandings, agreements, negotiations, representations and warranties, and communications, both written and oral in\n",
        "     relation to the subject matter of the Agreement.\"\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sum of word vectors\n",
        "def sent2vec(s):\n",
        "    words = str(s).lower()\n",
        "    words = tokenizer(words)\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(wv[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    return v / np.sqrt((v ** 2).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  calculate the cosine similarity\n",
        "def cos_sim(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_96392/2056317550.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return v / np.sqrt((v ** 2).sum())\n"
          ]
        }
      ],
      "source": [
        "legal_vec = [sent2vec(s) for s in s_legal]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "legal_similarity_matrix = np.zeros((7, 7))\n",
        "for i in range(7):\n",
        "    for j in range(7):\n",
        "        str1 = normalized_sum(s_legal[i])\n",
        "        str2 = normalized_sum(s_legal[j])\n",
        "\n",
        "        legal_similarity_matrix[i, j] = 1 - np.linalg.norm(str1 - str2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pyplot\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.42036647,  0.05415332,  0.05719644,  0.07875156,\n",
              "         0.14665604, -0.02347291],\n",
              "       [ 0.42036647,  1.        ,  0.04698986,  0.09012043,  0.12237865,\n",
              "         0.11325663,  0.01900166],\n",
              "       [ 0.05415332,  0.04698986,  1.        ,  0.37701154,  0.43116897,\n",
              "         0.25413394,  0.28274572],\n",
              "       [ 0.05719644,  0.09012043,  0.37701154,  1.        ,  0.38750178,\n",
              "         0.35486293,  0.28810358],\n",
              "       [ 0.07875156,  0.12237865,  0.43116897,  0.38750178,  1.        ,\n",
              "         0.32113504,  0.348086  ],\n",
              "       [ 0.14665604,  0.11325663,  0.25413394,  0.35486293,  0.32113504,\n",
              "         1.        ,  0.14315563],\n",
              "       [-0.02347291,  0.01900166,  0.28274572,  0.28810358,  0.348086  ,\n",
              "         0.14315563,  1.        ]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "legal_similarity_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ui_tokens = tokenizer(\"I want a bar chart with air data by traveller\")\n",
        "wv.most_similar_cosmul(positive=[ui_tokens], negative=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1e09bf56c0>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(legal_similarity_matrix, cmap='hot', interpolation='nearest')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
